# Docker Environment Configuration
# This file is used when running the application with Docker Compose
# Values here are used by all Docker services unless specifically overridden
# ----------------------------------------------------------------------------

# =============================================================================
# OpenAI API Configuration
# =============================================================================
# OpenAI API key (required for LLM and embeddings via AISuite)
OPENAI_API_KEY=
# Model ID with provider prefix for AISuite (format: "provider:model")
# Examples: openai:gpt-4o-mini, openai:gpt-4o, anthropic:claude-3-5-sonnet
OPENAI_MODEL=openai:gpt-4o-mini
OPENAI_EMBEDDING_MODEL=text-embedding-3-small
MAX_TOKENS=4096
# Temperature for LLM responses (0.0-2.0, default: 0.7)
LLM_TEMPERATURE=0.7

# =============================================================================
# API Configuration
# =============================================================================
# Admin API key for protected endpoints
ADMIN_API_KEY=dev_admin_key
# Cookie security setting - set to false for HTTP, true for HTTPS
COOKIE_SECURE=false
# Debug mode - note: can be overridden in docker-compose files based on environment
DEBUG=false

# =============================================================================
# CORS Configuration
# =============================================================================
# CORS_ORIGINS - comma-separated list of allowed origins
CORS_ORIGINS=http://localhost:3000,http://127.0.0.1:3000

# =============================================================================
# Data Paths Configuration
# =============================================================================
# Directory where application data is stored (must match volume mount in docker-compose.yml)
DATA_DIR=/data

# =============================================================================
# Bisq Integration Configuration
# =============================================================================
# Bisq API URL for fetching support chat data
# Use Docker network hostname in production: http://bisq2-api:8090
# Use localhost for local development outside Docker: http://localhost:8090
BISQ_API_URL=http://bisq2-api:8090

# Support agent nicknames (comma-separated list of official support staff)
# Required for FAQ extraction from support chats
# Example: SUPPORT_AGENT_NICKNAMES=suddenwhipvapor,strayorigin,toruk-makto
# If not configured, no messages will be marked as support messages
SUPPORT_AGENT_NICKNAMES=suddenwhipvapor

# =============================================================================
# Privacy and Security Settings
# =============================================================================
# Data retention period in days (GDPR compliance)
DATA_RETENTION_DAYS=30
# Enable privacy-preserving features (recommended for production)
ENABLE_PRIVACY_MODE=true
# Enable PII detection in logs
PII_DETECTION_ENABLED=true
# Log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO

# =============================================================================
# Port Configuration
# =============================================================================
# Direct port exposure (for direct access to services if needed)
EXPOSE_API_PORT=8000
EXPOSE_PROMETHEUS_PORT=9090
EXPOSE_GRAFANA_PORT=3001

# =============================================================================
# Monitoring Configuration
# =============================================================================
# Monitoring credentials
GRAFANA_ADMIN_USER=admin
GRAFANA_ADMIN_PASSWORD=securepassword
PROMETHEUS_BASIC_AUTH_USERNAME=admin
PROMETHEUS_BASIC_AUTH_PASSWORD=prometheuspassword

# Token cost tracking (for Prometheus metrics)
# These values should match your configured OPENAI_MODEL pricing
# Default values are for GPT-4o-mini (as of 2024):
#   - Input: $0.15 per 1M tokens = $0.00000015 per token
#   - Output: $0.60 per 1M tokens = $0.0000006 per token
# For other models, see: https://openai.com/api/pricing/
OPENAI_INPUT_COST_PER_TOKEN=0.00000015
OPENAI_OUTPUT_COST_PER_TOKEN=0.0000006

# External health monitoring (Healthchecks.io)
# Sign up at https://healthchecks.io and create a check with:
#   - Schedule: Every 15 minutes
#   - Grace Time: 5 minutes
# The health check script will ping this URL if all RAG metrics are healthy
HEALTHCHECK_URL=https://hc-ping.com/YOUR-UUID-HERE

# =============================================================================
# Matrix Alert Notifications (v0.9.0+)
# =============================================================================
# Matrix homeserver URL (e.g., https://matrix.org)
MATRIX_HOMESERVER_URL=https://matrix.org

# Matrix bot user (format: @username:homeserver.org)
MATRIX_USER=@bisq-alerts:matrix.org

# Matrix access token (NOT password)
# This is an access token obtained from your Matrix homeserver
# How to obtain:
#   Option 1: From existing account
#     - Log in to Element → Settings → Security & Privacy → Session Info
#     - Copy "Access Token" (keep it secure, acts like a password)
#   Option 2: Create via Matrix integration/bot registration
#     - Use homeserver admin API to register application service
#     - Use client API with m.login.password to get access token
# IMPORTANT: Keep this token secure - it provides full account access
MATRIX_TOKEN=your_access_token_here

# Matrix room IDs for alerts (format: !roomid:homeserver.org)
# Find room ID in Element: Room Settings → Advanced → Internal Room ID
# For multiple rooms, use comma-separated list: !room1:matrix.org,!room2:matrix.org
MATRIX_ROOMS=!YourRoomId:matrix.org

# API Settings
NEXT_PUBLIC_PROJECT_NAME="Bisq 2 Support Agent"
