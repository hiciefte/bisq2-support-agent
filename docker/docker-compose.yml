services:
  # Nginx reverse proxy for web frontend only
  nginx:
    image: nginx:alpine
    restart: unless-stopped
    environment:
      - API_URL=${API_URL:-/api} # For CSP configuration
    volumes:
      # Mount production config (with security headers enabled)
      - ./nginx/conf.d/default.prod.conf:/etc/nginx/conf.d/default.conf:ro
      # Mount other config files and snippets
      - ./nginx/conf.d/snippets:/etc/nginx/conf.d/snippets:ro
      - ./nginx/conf.d/tor-support.conf.template:/etc/nginx/conf.d/tor-support.conf.template:ro
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./logs/nginx:/var/log/nginx
      - ./nginx/error_pages:/usr/share/nginx/html/error_pages:ro
      # Mount maintenance page
      - ./maintenance/maintenance.html:/usr/share/nginx/html/maintenance.html:ro
    ports:
      # Bind to all interfaces for clearnet and Tor access
      - "0.0.0.0:80:80"
    depends_on:
      web:
        condition: service_healthy
      api:
        condition: service_healthy
    networks:
      - bisq-support-network
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:80" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.25'
          memory: 128M
    # Security hardening
    cap_drop:
      - ALL
    cap_add:
      - CHOWN
      - DAC_OVERRIDE
      - SETGID
      - SETUID
      - NET_BIND_SERVICE
    security_opt:
      - no-new-privileges:true
    read_only: true
    tmpfs:
      - /var/run
      - /var/cache/nginx
      - /tmp

  # Bisq2 API service
  bisq2-api:
    build:
      context: ./bisq2-api
      dockerfile: Dockerfile
      args:
        # Optional: uncomment and set if you need a different branch/repo
        # BISQ2_BRANCH: add-support-api
        # BISQ2_REPO_URL: https://github.com/hiciefte/bisq2.git
        APP_UID: 1001 # Match host user UID if needed for volume permissions
        APP_GID: 1001 # Match host user GID if needed for volume permissions
    restart: always
    volumes:
      - bisq2-data:/opt/bisq2/data
    environment:
      - BISQ_DATA_DIR=/opt/bisq2/data
      - JAVA_OPTS=-Xmx1g
    expose:
      - "8090"
    networks:
      - bisq-support-network
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8090/api/v1/support/export" ]
      interval: 30s
      timeout: 10s
      retries: 10
      start_period: 120s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4G
    cap_add:
      - NET_ADMIN
    security_opt:
      - seccomp:unconfined

  # API backend
  api:
    build:
      context: ..
      dockerfile: docker/api/Dockerfile
      args:
        - BUILD_ENV=production
        - APP_UID=${APP_UID:-1001}
        - APP_GID=${APP_GID:-1001}
    restart: unless-stopped
    volumes:
      - ../api/app:/app/app # Mount the app directory for development
      - ../api/data:/data # Mount the data directory
      # Named volume disabled: causes permission issues in local dev (root:root ownership)
      # - feedback-data:/data/feedback # Named volume for persistent feedback storage
      - matrix-session:/data/matrix_session # Matrix session persistence across restarts
    environment:
      # Only Docker-specific overrides here
      - ENVIRONMENT=production # Environment-specific setting
      # OpenAI API configuration (used by AISuite for LLM and embeddings)
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_MODEL=${OPENAI_MODEL}
      - OPENAI_EMBEDDING_MODEL=${OPENAI_EMBEDDING_MODEL}
      - MAX_TOKENS=${MAX_TOKENS}
      # Admin and security configuration
      - ADMIN_API_KEY=${ADMIN_API_KEY}
      - COOKIE_SECURE=${COOKIE_SECURE}
      - CORS_ORIGINS=${CORS_ORIGINS:-*}
      - DATA_DIR=${DATA_DIR:-/data}
      - BISQ_API_URL=${BISQ_API_URL:-http://bisq2-api:8090} # URL for the containerized Bisq2 API service
      # Tor hidden service configuration
      - TOR_HIDDEN_SERVICE=${TOR_HIDDEN_SERVICE}
      # Privacy and security settings
      - DATA_RETENTION_DAYS=${DATA_RETENTION_DAYS:-30}
      - SUPPORT_AGENT_NICKNAMES=${SUPPORT_AGENT_NICKNAMES}
      - ENABLE_PRIVACY_MODE=${ENABLE_PRIVACY_MODE:-true}
      - PII_DETECTION_ENABLED=${PII_DETECTION_ENABLED:-true}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      # Matrix shadow mode configuration
      - MATRIX_HOMESERVER_URL=${MATRIX_HOMESERVER_URL:-}
      - MATRIX_USER=${MATRIX_USER:-}
      - MATRIX_PASSWORD=${MATRIX_PASSWORD:-}
      - MATRIX_TOKEN=${MATRIX_TOKEN:-}
      - MATRIX_ROOMS=${MATRIX_ROOMS:-}
      - MATRIX_SESSION_FILE=${MATRIX_SESSION_FILE:-/data/matrix_session.json}
      # LLM classification configuration (Shadow Mode)
      - ENABLE_LLM_CLASSIFICATION=${ENABLE_LLM_CLASSIFICATION:-false}
      - LLM_CLASSIFICATION_MODEL=${LLM_CLASSIFICATION_MODEL:-openai:gpt-4o-mini}
      - LLM_PATTERN_CONFIDENCE_THRESHOLD=${LLM_PATTERN_CONFIDENCE_THRESHOLD:-0.85}
      - LLM_CLASSIFICATION_THRESHOLD=${LLM_CLASSIFICATION_THRESHOLD:-0.75}
      - LLM_CLASSIFICATION_CACHE_SIZE=${LLM_CLASSIFICATION_CACHE_SIZE:-1000}
      - LLM_CLASSIFICATION_CACHE_TTL_HOURS=${LLM_CLASSIFICATION_CACHE_TTL_HOURS:-1}
      - LLM_CLASSIFICATION_MAX_CONCURRENT=${LLM_CLASSIFICATION_MAX_CONCURRENT:-2}
      - LLM_CLASSIFICATION_TEMPERATURE=${LLM_CLASSIFICATION_TEMPERATURE:-0.2}
      - LLM_CLASSIFICATION_RATE_LIMIT_REQUESTS=${LLM_CLASSIFICATION_RATE_LIMIT_REQUESTS:-10}
      - LLM_CLASSIFICATION_RATE_LIMIT_WINDOW=${LLM_CLASSIFICATION_RATE_LIMIT_WINDOW:-60}
      # LLM question extraction configuration (Phase 1.5 - Full LLM Solution)
      - ENABLE_LLM_EXTRACTION=${ENABLE_LLM_EXTRACTION:-false}
      - LLM_EXTRACTION_MODEL=${LLM_EXTRACTION_MODEL:-openai:gpt-4o-mini}
      - LLM_EXTRACTION_TEMPERATURE=${LLM_EXTRACTION_TEMPERATURE:-0.0}
      - LLM_EXTRACTION_MAX_TOKENS=${LLM_EXTRACTION_MAX_TOKENS:-4000}
      - LLM_EXTRACTION_BATCH_SIZE=${LLM_EXTRACTION_BATCH_SIZE:-10}
      - LLM_EXTRACTION_CACHE_TTL=${LLM_EXTRACTION_CACHE_TTL:-3600}
      - LLM_EXTRACTION_CACHE_SIZE=${LLM_EXTRACTION_CACHE_SIZE:-100}
    expose:
      - "8000"
    networks:
      - bisq-support-network
    healthcheck:
      # Use localhost for more reliable health checking during startup
      test: [ "CMD", "curl", "-fsS", "--max-time", "5", "http://localhost:8000/health" ]
      interval: 15s
      timeout: 10s
      retries: 5
      start_period: 90s  # Extended to allow RAG service initialization (35-70s typical)
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4G
    # Security hardening
    cap_drop:
      - ALL
    cap_add:
      - CHOWN        # Required for entrypoint to fix file ownership
      - DAC_OVERRIDE # Required for entrypoint to bypass permission checks
      - SETGID       # Required for gosu to switch group
      - SETUID       # Required for gosu to switch user
    security_opt:
      - no-new-privileges:true

  # Web frontend
  web:
    build:
      context: ..
      dockerfile: docker/web/Dockerfile
      args:
        - BUILD_ENV=production
        - NEXT_PUBLIC_API_URL=/api
    restart: unless-stopped
    expose:
      - "3000"
    environment:
      - NEXT_PUBLIC_API_URL=/api # Production-specific for Nginx routing
      - NODE_ENV=production
      - NEXT_TELEMETRY_DISABLED=1
    command: npm run start
    depends_on:
      api:
        condition: service_healthy
    networks:
      - bisq-support-network
    healthcheck:
      test: [ "CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3000/" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
    # Security hardening
    cap_drop:
      - ALL
    security_opt:
      - no-new-privileges:true
    read_only: true
    tmpfs:
      - /tmp
      - /app/.next/cache

  # Monitoring - Prometheus
  prometheus:
    image: prom/prometheus:latest
    restart: always
    volumes:
      - ./prometheus:/etc/prometheus
      - prometheus-data:/prometheus
      - ../runtime_secrets/prometheus_admin_key:/etc/prometheus/admin_key:ro
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
    expose:
      - "9090"
    networks:
      - bisq-support-network
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M

  # Monitoring - Grafana
  grafana:
    image: grafana/grafana:latest
    restart: always
    volumes:
      - ./grafana/provisioning:/etc/grafana/provisioning:ro
      - ./grafana/dashboards:/var/lib/grafana/dashboards:ro
      - grafana-data:/var/lib/grafana
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_ADMIN_USER:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-securepassword}
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_AUTH_ANONYMOUS_ENABLED=false
      - GF_INSTALL_PLUGINS=yesoreyeram-infinity-datasource
      - ADMIN_API_KEY_FOR_GRAFANA=${ADMIN_API_KEY}
    ports:
      - "${EXPOSE_GRAFANA_PORT:-3001}:3000"
    depends_on:
      - prometheus
    networks:
      - bisq-support-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M

  # Node exporter for host metrics
  node-exporter:
    image: prom/node-exporter:latest
    restart: always
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.sysfs=/host/sys'
      - '--path.rootfs=/rootfs'
      - '--collector.filesystem.ignored-mount-points=^/(sys|proc|dev|host|etc)($$|/)'
    expose:
      - "9100"
    networks:
      - bisq-support-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '0.2'
          memory: 256M

  # cAdvisor for container metrics
  cadvisor:
    image: gcr.io/cadvisor/cadvisor:v0.47.0
    restart: always
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
      - /dev/disk/:/dev/disk:ro
    expose:
      - "8080"
    networks:
      - bisq-support-network
    privileged: true
    devices:
      - /dev/kmsg
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8080/healthz"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '0.3'
          memory: 512M

  # Alertmanager for alert routing and notification
  alertmanager:
    image: prom/alertmanager:v0.26.0
    restart: always
    volumes:
      - ./alertmanager:/etc/alertmanager
      - alertmanager-data:/alertmanager
    command:
      - '--config.file=/etc/alertmanager/alertmanager.yml'
      - '--storage.path=/alertmanager'
    expose:
      - "9093"
    networks:
      - bisq-support-network
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:9093/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '0.3'
          memory: 256M

  # Matrix webhook for alert notifications
  matrix-alertmanager-webhook:
    image: jaywink/matrix-alertmanager:v0.9.0
    restart: always
    environment:
      - MATRIX_HOMESERVER_URL=${MATRIX_HOMESERVER_URL}
      - MATRIX_USER=${MATRIX_USER}
      - MATRIX_TOKEN=${MATRIX_TOKEN}
      - MATRIX_ROOMS=${MATRIX_ROOMS}
      - APP_PORT=3000
    expose:
      - "3000"
    networks:
      - bisq-support-network
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '0.2'
          memory: 128M

  # Scheduler for periodic tasks
  scheduler:
    image: alpine:latest
    restart: always
    environment:
      - PROMETHEUS_URL=http://prometheus:9090
      - HEALTHCHECK_URL=${HEALTHCHECK_URL:-https://hc-ping.com/27867359-f4f3-4e22-8f46-8d18a73cf219}
      - ADMIN_API_KEY=${ADMIN_API_KEY}
      - API_HOST=api:8000
    volumes:
      - ./scripts:/scripts:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - ./logs/cron:/var/log/cron
    command: >
      sh -c "
        apk add --no-cache docker-cli docker-compose bash coreutils curl jq bc &&
        mkdir -p /var/log/cron &&
        # Add @reboot entries to run scripts once when crond starts
        echo '@reboot /scripts/update-faqs.sh >> /var/log/cron/faqs.log 2>&1' > /etc/crontabs/root &&
        echo '@reboot /scripts/process-feedback.sh >> /var/log/cron/feedback.log 2>&1' >> /etc/crontabs/root &&
        # Add regular cron entries
        echo '0 1 * * 0 /scripts/update-wiki.sh >> /var/log/cron/wiki.log 2>&1' >> /etc/crontabs/root &&
        echo '0 0 * * * /scripts/update-faqs.sh >> /var/log/cron/faqs.log 2>&1' >> /etc/crontabs/root &&
        echo '0 0 * * 1 /scripts/process-feedback.sh >> /var/log/cron/feedback.log 2>&1' >> /etc/crontabs/root &&
        echo '*/15 * * * * /scripts/rag-health-check.sh >> /var/log/cron/rag-health.log 2>&1' >> /etc/crontabs/root &&
        echo '*/30 * * * * /scripts/poll-matrix.sh >> /var/log/cron/matrix-poll.log 2>&1' >> /etc/crontabs/root &&
        # Start cron daemon in foreground, logging verbosely to stderr (which goes to docker logs)
        crond -f -l 8 -d 8
      "
    depends_on:
      api:
        condition: service_healthy
      prometheus:
        condition: service_healthy
      alertmanager:
        condition: service_healthy
    networks:
      - bisq-support-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

volumes:
  prometheus-data:
  grafana-data:
  alertmanager-data:
  web_node_modules:
    name: bisq2-web-node-modules
  bisq2-data:
    name: bisq2-data
  feedback-data:
    name: bisq2-feedback-data
    driver: local
  matrix-session:
    name: bisq2-matrix-session
    driver: local

networks:
  bisq-support-network:
    driver: bridge
